{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70890c7f",
   "metadata": {},
   "source": [
    "#### 1. Provide an example of the concepts of Prior, Posterior, and Likelihood.\n",
    "\n",
    "- Prior: The prior probability represents our initial belief or probability about an email being spam or ham, without considering any specific evidence. For example, let's say we know that historically 20% of all emails received are spam. This means our prior probability of an email being spam is 0.2, and the prior probability of it being ham is 0.8.\n",
    "\n",
    "- Likelihood: The likelihood represents the probability of observing the given evidence (features) given a specific class (spam or ham). In our example, let's say we have identified three features: the presence of certain keywords, the number of exclamation marks, and the length of the email. We can calculate the likelihood of these features for spam emails and ham emails separately. For instance, we find that 90% of spam emails contain specific keywords, while only 10% of ham emails do.\n",
    "\n",
    "- Posterior: The posterior probability is the updated probability of the class (spam or ham) given the observed evidence. It is obtained by applying Bayes' theorem. Using the prior and likelihood, we can calculate the posterior probability. Let's say we receive an email with the identified features: keywords present, three exclamation marks, and a short length. We can use Bayes' theorem to calculate the posterior probabilities of it being spam or ham based on the prior probabilities and likelihoods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e986073",
   "metadata": {},
   "source": [
    "#### 2. What role does Bayes&#39; theorem play in the concept learning principle?\n",
    "Bayes' theorem plays a crucial role in the concept learning principle, particularly in the context of Bayesian inference and probabilistic reasoning. The concept learning principle aims to infer or learn a concept based on observed data or evidence.\n",
    "\n",
    "In the context of concept learning, Bayes' theorem allows us to update our beliefs or hypotheses about a concept given new evidence or observed data. It provides a formal framework for combining prior knowledge or beliefs with observed data to make inferences and update our understanding of the concept.\n",
    "\n",
    "Bayes' theorem allows us to calculate the posterior probability of a hypothesis or concept given the observed data, by incorporating the prior probability (initial belief) and the likelihood (probability of observing the data given the hypothesis). By iteratively updating the probabilities as new data is observed, we can refine our understanding of the concept and make more accurate predictions or classifications.`m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a54884d",
   "metadata": {},
   "source": [
    "#### 4. Can the Nave Bayes classifier be used on continuous numeric data? If so, how can you go about doing it?\n",
    "\n",
    "Yes, the Naive Bayes classifier can be used on continuous numeric data. However, since the Naive Bayes classifier assumes independence between features, it requires an additional step to handle continuous data appropriately. There are two common approaches to handle continuous data with Naive Bayes:\n",
    "\n",
    "Discretization: One way to use Naive Bayes with continuous data is to discretize the numeric features into discrete intervals or bins. This means converting the continuous values into categories or ranges. This can be done by dividing the range of values into equal-width bins or using more sophisticated techniques such as equal-frequency binning or entropy-based binning. Once the data is discretized, the Naive Bayes classifier can be applied as usual, treating each bin as a separate category.\n",
    "\n",
    "Gaussian Naive Bayes: Another approach is to assume that the continuous data follows a Gaussian (normal) distribution. In this case, the Naive Bayes classifier can be modified to use a Gaussian distribution for each feature. Instead of computing probabilities based on counts or frequencies, the classifier calculates the mean and standard deviation of each feature for each class. Then, it uses the probability density function (PDF) of the Gaussian distribution to estimate the likelihood of a given value belonging to a particular class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddb149c",
   "metadata": {},
   "source": [
    "#### 5. What are Bayesian Belief Networks, and how do they work? What are their applications? Are they capable of resolving a wide range of issues?\n",
    "\n",
    "Bayesian Belief Networks (BBNs), also known as Bayesian networks or graphical models, are probabilistic graphical models that represent and reason about uncertain knowledge using the principles of Bayesian probability theory. BBNs are composed of nodes representing random variables or events and directed edges representing probabilistic dependencies between the variables. These dependencies are typically encoded using conditional probability distributions (CPDs).\n",
    "\n",
    "BBNs work by utilizing Bayes' theorem and graphical modeling techniques to perform probabilistic inference. They can be used to compute various types of probabilities, such as marginal probabilities, conditional probabilities, and joint probabilities, based on the observed evidence and prior knowledge encoded in the network. The network structure allows for efficient and systematic propagation of probabilities through the graph, enabling inference about unobserved variables given the observed variables.\n",
    "\n",
    "BBNs have a wide range of applications in various fields, including:\n",
    "\n",
    "- Decision Making: BBNs can model decision problems by integrating probabilistic information with decision nodes representing actions or choices. They can help in making optimal decisions under uncertainty by evaluating the expected utility of different choices.\n",
    "\n",
    "- Diagnosis and Prediction: BBNs are used for medical diagnosis, fault diagnosis in engineering systems, and predictive modeling in areas such as finance and weather forecasting. They can combine prior knowledge with observed symptoms or measurements to infer the most likely causes or predict future outcomes.\n",
    "\n",
    "- Risk Assessment: BBNs are employed in risk analysis and management to assess and quantify risks in complex systems. They can model the dependencies between various risk factors and estimate the probabilities of different risk events or scenarios.\n",
    "\n",
    "- Information Retrieval: BBNs are used in information retrieval systems to model relevance and perform probabilistic ranking of documents based on query terms and observed evidence.\n",
    "\n",
    "\n",
    "while BBNs are powerful tools for probabilistic modeling and inference, they have certain limitations. The effectiveness of BBNs depends on the quality of the model structure and the availability of accurate prior knowledge and data. They may face challenges in handling large-scale problems due to computational complexity. Additionally, BBNs assume that variables are conditionally independent given their parents in the graphical model, which may not always hold in real-world scenarios. Nonetheless, BBNs have proven to be valuable tools for modeling and reasoning under uncertainty in a wide range of domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e38df",
   "metadata": {},
   "source": [
    "**6. Passengers are checked in an airport screening system to see if there is an intruder. Let I be the\n",
    "random variable that indicates whether someone is an intruder I = 1) or not I = 0), and A be the\n",
    "variable that indicates alarm I = 0). If an intruder is detected with probability P(A = 1|I = 1) = 0.98\n",
    "and a non-intruder is detected with probability P(A = 1|I = 0) = 0.001, an alarm will be triggered,\n",
    "implying the error factor. The likelihood of an intruder in the passenger population is P(I = 1) =\n",
    "0.00001. What are the chances that an alarm would be triggered when an individual is actually an\n",
    "intruder?**\n",
    "\n",
    "Let's denote:\n",
    "I = event that someone is an intruder (I = 1 if intruder, I = 0 if non-intruder)\n",
    "A = event that an alarm is triggered (A = 1 if alarm triggered, A = 0 if no alarm)\n",
    "\n",
    "We are given the following probabilities:\n",
    "P(A = 1|I = 1) = 0.98 (probability of an alarm given that the person is an intruder)\n",
    "P(A = 1|I = 0) = 0.001 (probability of an alarm given that the person is a non-intruder)\n",
    "P(I = 1) = 0.00001 (probability of an individual being an intruder)\n",
    "\n",
    "We want to find P(I = 1|A = 1), which represents the probability of an individual being an intruder given that an alarm is triggered.\n",
    "\n",
    "Using Bayes' theorem, we have:\n",
    "\n",
    "P(I = 1|A = 1) = (P(A = 1|I = 1) * P(I = 1)) / P(A = 1)\n",
    "\n",
    "To calculate P(A = 1), we can use the law of total probability:\n",
    "P(A = 1) = P(A = 1|I = 1) * P(I = 1) + P(A = 1|I = 0) * P(I = 0)\n",
    "\n",
    "Given the probabilities, we can substitute the values into the formula:\n",
    "\n",
    "P(A = 1) = (0.98 * 0.00001) + (0.001 * (1 - 0.00001))\n",
    "\n",
    "Now we can calculate P(I = 1|A = 1) using Bayes' theorem:\n",
    "\n",
    "P(I = 1|A = 1) = (0.98 * 0.00001) / P(A = 1)\n",
    "\n",
    "\n",
    "To calculate P(I = 1|A = 1), we need to substitute the values into the formula:\n",
    "\n",
    "P(A = 1) = (0.98 * 0.00001) + (0.001 * (1 - 0.00001))\n",
    "= 0.0000098 + 0.000999\n",
    "= 0.000010799\n",
    "\n",
    "Now we can calculate P(I = 1|A = 1) using Bayes' theorem:\n",
    "\n",
    "P(I = 1|A = 1) = (0.98 * 0.00001) / P(A = 1)\n",
    "= (0.98 * 0.00001) / 0.000010799\n",
    "≈ 0.9068\n",
    "\n",
    "Therefore, the chances that an alarm would be triggered when an individual is actually an intruder, P(I = 1|A = 1), is approximately 0.9068 or 90.68%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebe16bb",
   "metadata": {},
   "source": [
    "**7. An antibiotic resistance test (random variable T) has 1% false positives (i.e., 1% of those who are\n",
    "not immune to an antibiotic display a positive result in the test) and 5% false negatives (i.e., 1% of\n",
    "those who are not resistant to an antibiotic show a positive result in the test) (i.e. 5 percent of those\n",
    "actually resistant to an antibiotic test negative). Assume that 2% of those who were screened were\n",
    "antibiotic-resistant. Calculate the likelihood that a person who tests positive is actually immune\n",
    "(random variable D).**\n",
    "\n",
    "P(D = 1) = 0.02 (probability that a person is actually immune)\n",
    "P(D = 0) = 1 - P(D = 1) = 0.98 (probability that a person is not immune)\n",
    "\n",
    "P(T = 1|D = 0) = 0.01 (probability of a false positive)\n",
    "P(T = 0|D = 1) = 0.05 (probability of a false negative)\n",
    "\n",
    "We want to calculate P(D = 1|T = 1), the probability that a person is actually immune given that they tested positive.\n",
    "\n",
    "Using Bayes' theorem, we have:\n",
    "\n",
    "P(D = 1|T = 1) = (P(T = 1|D = 1) * P(D = 1)) / P(T = 1)\n",
    "\n",
    "To calculate P(T = 1), we can use the law of total probability:\n",
    "\n",
    "P(T = 1) = P(T = 1|D = 1) * P(D = 1) + P(T = 1|D = 0) * P(D = 0)\n",
    "\n",
    "P(T = 1) = (0.05 * 0.02) + (0.01 * 0.98) = 0.001 + 0.0098 = 0.0108\n",
    "\n",
    "Now we can substitute the values into the equation for P(D = 1|T = 1):\n",
    "\n",
    "P(D = 1|T = 1) = (0.05 * 0.02) / 0.0108 ≈ 0.0926\n",
    "\n",
    "Therefore, the likelihood that a person who tests positive is actually immune (D = 1) is approximately 0.0926 or 9.26%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4a8e3c",
   "metadata": {},
   "source": [
    "**8. In order to prepare for the test, a student knows that there will be one question in the exam that\n",
    "is either form A, B, or C. The chances of getting an A, B, or C on the exam are 30 percent, 20%, and\n",
    "50 percent, respectively. During the planning, the student solved 9 of 10 type A problems, 2 of 10\n",
    "type B problems, and 6 of 10 type C problems.**\n",
    "\n",
    "1. What is the likelihood that the student can solve the exam problem?\n",
    "\n",
    "2. Given the student&#39;s solution, what is the likelihood that the problem was of form A?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ba75e4",
   "metadata": {},
   "source": [
    "\n",
    "To calculate the likelihood that the student can solve the exam problem, we can use Bayes' theorem. Let's define the following probabilities:\n",
    "\n",
    "P(A) = 0.3 (probability of getting a problem of form A)\n",
    "P(B) = 0.2 (probability of getting a problem of form B)\n",
    "P(C) = 0.5 (probability of getting a problem of form C)\n",
    "\n",
    "P(S|A) = 9/10 (likelihood of solving a type A problem)\n",
    "P(S|B) = 2/10 (likelihood of solving a type B problem)\n",
    "P(S|C) = 6/10 (likelihood of solving a type C problem)\n",
    "\n",
    "To calculate the likelihood that the student can solve the exam problem, we can use the law of total probability:\n",
    "P(S) = P(A) * P(S|A) + P(B) * P(S|B) + P(C) * P(S|C)\n",
    "\n",
    "P(S) = 0.3 * (9/10) + 0.2 * (2/10) + 0.5 * (6/10)\n",
    "= 0.27 + 0.04 + 0.3\n",
    "= 0.61\n",
    "\n",
    "Therefore, the likelihood that the student can solve the exam problem is 0.61 or 61%.\n",
    "\n",
    "To calculate the likelihood that the problem was of form A given the student's solution, we can use Bayes' theorem:\n",
    "P(A|S) = (P(S|A) * P(A)) / P(S)\n",
    "\n",
    "P(A|S) = (9/10 * 0.3) / 0.61\n",
    "= 0.27 / 0.61\n",
    "≈ 0.443\n",
    "\n",
    "Therefore, the likelihood that the problem was of form A given the student's solution is approximately 0.443 or 44.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a61ccd9",
   "metadata": {},
   "source": [
    "**9. A bank installs a CCTV system to track and photograph incoming customers. Despite the constant\n",
    "influx of customers, we divide the timeline into 5 minute bins. There may be a customer coming into\n",
    "the bank with a 5% chance in each 5-minute time period, or there may be no customer (again, for\n",
    "simplicity, we assume that either there is 1 customer or none, not the case of multiple customers)**.\n",
    "\n",
    "If there is a client, the CCTV will detect them with a 99 percent probability. If there is no customer, the\n",
    "   camera can take a false photograph with a 10% chance of detecting movement from other objects.\n",
    "\n",
    "    1. How many customers come into the bank on a daily basis (10 hours)?\n",
    "\n",
    "    2. On a daily basis, how many fake photographs (photographs taken when there is no\n",
    "        customer) and how many missed photographs (photographs taken when there is a customer) are\n",
    "        there?\n",
    "\n",
    "    3. Explain likelihood that there is a customer if there is a photograph?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c786eb",
   "metadata": {},
   "source": [
    "**1->**To calculate the number of customers coming into the bank on a daily basis (10 hours), we first need to determine the number of 5-minute time periods in 10 hours.\n",
    "There are 10 hours * 60 minutes = 600 minutes in total.\n",
    "Since each time period is 5 minutes, the number of time periods in 10 hours is 600 minutes / 5 minutes = 120.\n",
    "\n",
    "The probability of a customer coming into the bank in each 5-minute time period is 5% or 0.05. Therefore, the expected number of customers on a daily basis is 120 time periods * 0.05 = 6 customers.\n",
    "\n",
    "**2->**To calculate the number of fake photographs and missed photographs on a daily basis, we need to consider the probabilities of false detection and missed detection.\n",
    "The probability of a false photograph being taken when there is no customer is 10% or 0.1. The probability of a customer being missed (no photograph taken) is 1% or 0.01.\n",
    "\n",
    "The number of fake photographs on a daily basis is 120 time periods * 0.1 = 12 photographs.\n",
    "The number of missed photographs on a daily basis is 6 customers * 120 time periods * 0.01 = 7.2 photographs (since we assume either there is 1 customer or none, we round this to the nearest whole number).\n",
    "\n",
    "**3->**The likelihood that there is a customer if there is a photograph can be calculated using Bayes' theorem:\n",
    "P(Customer|Photograph) = (P(Photograph|Customer) * P(Customer)) / P(Photograph)\n",
    "\n",
    "Given that the probability of a photograph being taken when there is a customer is 99% or 0.99, and the probability of a customer coming into the bank is 5% or 0.05, we have:\n",
    "\n",
    "P(Customer|Photograph) = (0.99 * 0.05) / P(Photograph)\n",
    "\n",
    "To calculate P(Photograph), we need to consider both the probability of a photograph when there is a customer and the probability of a photograph when there is no customer:\n",
    "\n",
    "P(Photograph) = P(Photograph|Customer) * P(Customer) + P(Photograph|No Customer) * P(No Customer)\n",
    "= 0.99 * 0.05 + 0.1 * 0.95\n",
    "= 0.0495 + 0.095\n",
    "= 0.1445\n",
    "\n",
    "Therefore, the likelihood that there is a customer if there is a photograph is:\n",
    "\n",
    "P(Customer|Photograph) = (0.99 * 0.05) / 0.1445\n",
    "≈ 0.342"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74968538",
   "metadata": {},
   "source": [
    "***10. Create the conditional probability table associated with the node Won Toss in the Bayesian Belief\n",
    "network to represent the conditional independence assumptions of the Nave Bayes classifier for the\n",
    "match winning prediction problem in Section 6.4.4.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69836927",
   "metadata": {},
   "source": [
    "To create the conditional probability table (CPT) for the \"Won Toss\" node in the Naive Bayes classifier, we need to make conditional independence assumptions based on the problem at hand. In this case, let's assume that the \"Won Toss\" node depends only on the \"Home Ground Advantage\" node and the \"Team Strength\" node.\n",
    "\n",
    "The possible values for the \"Won Toss\" node are \"Yes\" and \"No\". The possible values for the \"Home Ground Advantage\" node are \"Yes\" and \"No\". The possible values for the \"Team Strength\" node are \"Strong\" and \"Weak\".\n",
    "\n",
    "The conditional probability table for the \"Won Toss\" node can be represented as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3434edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "| Home Ground Advantage | Team Strength | P(Won Toss = Yes) | P(Won Toss = No) |\n",
    "|-----------------------|---------------|------------------|-----------------|\n",
    "| Yes                   | Strong        | p1               | p2              |\n",
    "| Yes                   | Weak          | p3               | p4              |\n",
    "| No                    | Strong        | p5               | p6              |\n",
    "| No                    | Weak          | p7               | p8              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da014c38",
   "metadata": {},
   "source": [
    "Here, p1, p2, p3, p4, p5, p6, p7, and p8 represent the probabilities corresponding to each combination of values. These probabilities need to be estimated or obtained from the training data using appropriate methods (e.g., maximum likelihood estimation).\n",
    "\n",
    "Note that the assumption of conditional independence allows us to specify the probabilities for the \"Won Toss\" node based on the individual probabilities of the \"Home Ground Advantage\" and \"Team Strength\" nodes, without considering any direct dependency between the two parent nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44df83d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
